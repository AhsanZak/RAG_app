# RAG Chat Application

An AI-powered chat application built with FastAPI (backend) and React + Ant Design (frontend) featuring Retrieval-Augmented Generation (RAG). You can upload PDFs, vectorize them with language-aware embeddings, and chat over their content using a local or remote LLM.

## Project Structure

```
RAG_App/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ main.py             # Main FastAPI application
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ .gitignore         # Python gitignore
â”œâ”€â”€ frontend/               # React.js frontend
â”‚   â”œâ”€â”€ public/            # Static files
â”‚   â”œâ”€â”€ src/               # React source code
â”‚   â”‚   â”œâ”€â”€ App.js         # Main React component
â”‚   â”‚   â”œâ”€â”€ index.js       # React entry point
â”‚   â”‚   â””â”€â”€ index.css      # Global styles
â”‚   â”œâ”€â”€ package.json       # Node.js dependencies
â”‚   â””â”€â”€ .gitignore         # Node.js gitignore
â””â”€â”€ README.md              # This file
```

## Key Features (Current)

- ğŸ¤– Chat over documents with RAG (ChromaDB for vector storage)
- ğŸ“„ PDF ingestion with OCR fallback for scanned/image-based PDFs
- ğŸŒ Language detection and auto-embedding model selection
- ğŸ§© Embedding models from configuration (no DB required), on-demand download
- ğŸ§  LLM model management (e.g., Ollama/OpenAI) with model selector in UI
- ğŸ–¥ï¸ Clean PDF chat UI (static upload area + scrollable sessions list)
- ğŸ“ First message preview/summary after processing for quick verification

## Current Status

- âœ… FastAPI backend with PDF upload, processing (OCR), chat endpoints
- âœ… Embedding models config with downloadable models (HuggingFace)
- âœ… React UI for PDF chat, LLM model selection, embedding selection
- âœ… ChromaDB integration with robust metadata handling
- âœ… Sessions, messages, and collection existence checks

## Getting Started

### Prerequisites

- Python 3.8+
- Node.js 16+
- npm or yarn
- System OCR dependencies (for scanned PDFs):
  - Tesseract OCR
    - Windows: install Tesseract and add `tesseract.exe` to PATH
    - Linux: `sudo apt install tesseract-ocr`
    - macOS: `brew install tesseract`
  - Poppler (for `pdf2image`)
    - Windows: install Poppler and add its `bin` folder to PATH
    - Linux: `sudo apt install poppler-utils`
    - macOS: `brew install poppler`

### Backend Setup

1. Navigate to the backend directory:
   ```bash
   cd backend
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Run the FastAPI server:
   ```bash
   python main.py
   ```

   The API will be available at `http://localhost:8000`
   - API Documentation: `http://localhost:8000/docs`
   - Alternative docs: `http://localhost:8000/redoc`

Backend dependencies to note (pip-installed):

- `pdf2image`, `pytesseract`, `Pillow`, `langdetect`, `pdfplumber`, `PyPDF2`, `chromadb`, `sentence-transformers`, `huggingface-hub`

### Frontend Setup

1. Navigate to the frontend directory:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Start the development server:
   ```bash
   npm start
   ```

   The frontend will be available at `http://localhost:3000`

## API Endpoints

Core

- `GET /` â€“ root health
- `GET /health` â€“ health check
- `GET /api/endpoints` â€“ list endpoints

Embedding models (from configuration file `backend/config/embedding_models.py`)

- `GET /api/embedding-models` â€“ list available embedding models
- `GET /api/embedding-models/by-name/{model_name}` â€“ details for one model
- `POST /api/embedding-models/{model_name}/download` â€“ download model (on-demand)
- `GET /api/embedding-models/status|test|direct` â€“ diagnostics

PDF workflow

- `POST /api/pdf/upload` â€“ upload a PDF (returns extracted chunks, `pdf_type`, and sample text)
- `POST /api/pdf/process` â€“ vectorize chunks into ChromaDB (OCR fallback, language detect, preview summary)
- `POST /api/pdf/chat` â€“ RAG query against the sessionâ€™s collection
- `GET /api/sessions` â€“ list sessions (includes `hasVectorizedData` and `collection_name`)
- `GET /api/sessions/{session_id}/messages` â€“ list messages for a session

## How it Works (Highlights)

1. Upload: `/api/pdf/upload` extracts text with `pdfplumber`/`PyPDF2`. If no text is found, OCR fallback (`pdf2image` + `pytesseract`) attempts extraction. Returns `pdf_type` for UI info.
2. Process: `/api/pdf/process` chunks data, auto-detects language (`langdetect`), auto-selects embedding model (Arabic â†’ `BAAI/bge-m3`, English â†’ `all-mpnet-base-v2`, otherwise â†’ `intfloat/multilingual-e5-base`), generates embeddings, and stores them in ChromaDB. It also saves a first assistant message with a preview/summary.
3. Chat: `/api/pdf/chat` retrieves relevant chunks from ChromaDB and generates answers using the selected LLM.

Guards

- If no text is found after OCR, processing returns `400` with a clear message instead of failing inside ChromaDB.
- Before chat, the server checks that the sessionâ€™s collection exists.

## Technology Stack

- **Backend**: FastAPI, SQLAlchemy, ChromaDB
- **Frontend**: React.js, Ant Design
- **Embeddings**: sentence-transformers/HF models (config-driven)
- **OCR**: Tesseract via `pytesseract`, `pdf2image`, `Pillow`
- **LLM**: pluggable (e.g., Ollama/OpenAI) via model selector

## Troubleshooting

- Scanned PDF still fails
  - Ensure Tesseract and Poppler are installed and on PATH.
  - Check backend logs for lines starting with `[PDF]` / `[PDF][OCR]` / `[UPLOAD]` / `[PROCESS]`.
- Embedding model list is empty
  - Check `GET /api/embedding-models/status` and `GET /api/embedding-models`.
  - Confirm `backend/config/embedding_models.py` exists and is importable.
- ChromaDB telemetry warnings
  - Telemetry is disabled in the service; warnings can be ignored if present.

## License

This project is for educational and development purposes.
